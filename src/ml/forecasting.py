"""
–ú–æ–¥—É–ª—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –¥–≤–∏–≥–∞—Ç–µ–ª–µ–π

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–µ–Ω–¥—ã RMS —Ç–æ–∫–æ–≤ –ø–æ —Ñ–∞–∑–∞–º –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ:
- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ RMS –¥–ª—è –∫–∞–∂–¥–æ–π —Ñ–∞–∑—ã
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ ARIMA –∏ Prophet –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
- –†–∞—Å—á–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ø–æ—Ä–æ–≥–æ–≤ (–∞–Ω–æ–º–∞–ª–∏–∏)
- –†–∞–±–æ—Ç–∞ –±–µ–∑ –º–µ—Ç–æ–∫ –æ—Ç–∫–∞–∑–æ–≤ (unsupervised –ø–æ–¥—Ö–æ–¥)
"""

import warnings
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Union
from uuid import UUID

import numpy as np
import pandas as pd
from prophet import Prophet
from sklearn.preprocessing import StandardScaler
from sqlalchemy import select, and_
from sqlalchemy.ext.asyncio import AsyncSession
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller

from src.config.settings import get_settings
from src.database.connection import get_async_session
from src.database.models import Feature, Equipment, RawSignal
from src.utils.logger import get_logger

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
settings = get_settings()
logger = get_logger(__name__)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
DEFAULT_FORECAST_STEPS = 24  # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 24 —à–∞–≥–∞ –≤–ø–µ—Ä–µ–¥
DEFAULT_ANOMALY_THRESHOLD = 1.5  # –ü–æ—Ä–æ–≥ –∞–Ω–æ–º–∞–ª–∏–∏ (–≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è—Ö)
MIN_OBSERVATIONS = 50  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
SEASONALITY_PERIOD = 24  # –ü–µ—Ä–∏–æ–¥ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ (24 —á–∞—Å–∞)


class ForecastingError(Exception):
    """–ë–∞–∑–æ–≤–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"""
    pass


class InsufficientDataError(ForecastingError):
    """–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö"""
    pass


# === MVP —Ñ—É–Ω–∫—Ü–∏—è forecast_rms —Å–æ–≥–ª–∞—Å–Ω–æ –∫–æ–Ω—Ç—Ä–∞–∫—Ç—É ===
async def forecast_rms(equipment_id: UUID, n_steps: int = 24, threshold_sigma: float = 2.0):
    """–£–ø—Ä–æ—â—ë–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ RMS –ø–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é.

    –ê–ª–≥–æ—Ä–∏—Ç–º (MVP):
      1. –ó–∞–≥—Ä—É–∂–∞–µ–º RMS (rms_a, rms_b, rms_c) –∏–∑ Feature –ø–æ –¥–∞–Ω–Ω–æ–º—É equipment_id —á–µ—Ä–µ–∑ —Å–≤—è–∑—å RawSignal.
      2. –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Å—Ä–µ–¥–Ω–∏–π RMS (—Å—Ä–µ–¥–Ω–µ–µ –ø–æ –¥–æ—Å—Ç—É–ø–Ω—ã–º —Ñ–∞–∑–∞–º) –ø–æ –≤—Ä–µ–º–µ–Ω–∏ window_start (—á–∞—Å–æ–≤–æ–µ –æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ).
      3. –ï—Å–ª–∏ —Ç–æ—á–µ–∫ < MIN_OBSERVATIONS -> InsufficientDataError.
      4. –ü—Ä–æ–≥–Ω–æ–∑: –ø—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Prophet; –µ—Å–ª–∏ –Ω–µ—Ç (ImportError) ‚Äì fallback –Ω–∞ –ø—Ä–æ—Å—Ç—É—é —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å (moving average) –∏–ª–∏ ARIMA(1,0,0).
      5. –û—Ü–µ–Ω–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ø–æ—Ä–æ–≥–∞: –±–µ—Ä—ë–º sigma –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–≥–æ —Ä—è–¥–∞; threshold = mean + threshold_sigma*std; –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è > threshold ‚Äì –æ—Ü–µ–Ω–∏–≤–∞–µ–º p –∫–∞–∫ –¥–æ–ª—é.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å forecast, threshold –∏ probability_over_threshold.
    """
    from sqlalchemy import select
    from src.database.connection import get_async_session
    from src.database.models import Feature, RawSignal

    async with get_async_session() as session:
        # Join Feature -> RawSignal —á—Ç–æ–±—ã —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ equipment_id
        q = select(Feature).join(RawSignal).where(RawSignal.equipment_id == equipment_id).order_by(Feature.window_start.asc())
        res = await session.execute(q)
        feats = res.scalars().all()

    if len(feats) < MIN_OBSERVATIONS:
        raise InsufficientDataError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(feats)} < {MIN_OBSERVATIONS}")

    import pandas as pd
    rows = []
    for f in feats:
        values = [v for v in [f.rms_a, f.rms_b, f.rms_c] if v is not None]
        if not values:
            continue
        rows.append({
            'ts': f.window_start,
            'rms_mean': float(np.mean(values))
        })
    df = pd.DataFrame(rows)
    if df.empty or len(df) < MIN_OBSERVATIONS:
        raise InsufficientDataError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö RMS –∑–Ω–∞—á–µ–Ω–∏–π")

    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ —á–∞—Å—É
    df['ts_hour'] = pd.to_datetime(df['ts']).dt.floor('H')
    hourly = df.groupby('ts_hour')['rms_mean'].mean().reset_index().rename(columns={'ts_hour':'ds','rms_mean':'y'})

    series = hourly['y']
    mu = series.mean()
    sigma = series.std(ddof=0) or 1e-6
    threshold = mu + threshold_sigma * sigma

    forecast_values = []
    future_index = []
    try:
        from prophet import Prophet  # type: ignore
        m = Prophet(daily_seasonality=True, weekly_seasonality=False, yearly_seasonality=False)
        m.fit(hourly)
        future = m.make_future_dataframe(periods=n_steps, freq='H', include_history=False)
        fc = m.predict(future)
        forecast_values = fc['yhat'].tolist()
        future_index = future['ds'].tolist()
    except Exception:
        # Fallback: –ø—Ä–æ—Å—Ç–æ–µ —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–∫–Ω–∞
        window = min(12, len(series))
        last_ma = series.rolling(window).mean().iloc[-1]
        trend = (series.iloc[-1] - series.iloc[-window]) / max(window-1,1)
        for i in range(1, n_steps+1):
            forecast_values.append(float(last_ma + trend * i))
        import pandas as pd
        last_ts = hourly['ds'].iloc[-1]
        future_index = [last_ts + pd.Timedelta(hours=i) for i in range(1, n_steps+1)]

    over = [v for v in forecast_values if v > threshold]
    probability_over = len(over)/len(forecast_values) if forecast_values else 0.0

    return {
        'equipment_id': str(equipment_id),
        'history_points': len(series),
        'threshold': threshold,
        'forecast': [
            {'timestamp': ts.isoformat(), 'rms': float(v), 'over_threshold': v > threshold}
            for ts, v in zip(future_index, forecast_values)
        ],
        'probability_over_threshold': probability_over,
        'model': 'Prophet' if 'Prophet' in globals() and 'm' in locals() else 'FallbackMA'
    }


class TimeSeriesPreprocessor:
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤"""
    
    def __init__(self):
        self.logger = get_logger(f"{__name__}.{self.__class__.__name__}")
        
    def prepare_time_series(
        self, 
        df: pd.DataFrame, 
        value_column: str,
        time_column: str = 'timestamp'
    ) -> pd.DataFrame:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            value_column: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å–æ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            time_column: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
            
        Returns:
            –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π DataFrame
        """
        # –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        ts_df = df.copy()
        
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        ts_df = ts_df.dropna(subset=[value_column])
        
        if len(ts_df) < MIN_OBSERVATIONS:
            raise InsufficientDataError(
                f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(ts_df)} < {MIN_OBSERVATIONS}"
            )
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        ts_df = ts_df.sort_values(time_column)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        duplicates = ts_df[time_column].duplicated()
        if duplicates.any():
            self.logger.warning(f"–ù–∞–π–¥–µ–Ω–æ {duplicates.sum()} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏, —É–¥–∞–ª—è–µ–º")
            ts_df = ts_df[~duplicates]
        
        # –†–µ—Å–µ–º–ø–ª–∏–Ω–≥ –∫ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–π —Å–µ—Ç–∫–µ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        ts_df = self._resample_to_regular_grid(ts_df, time_column, value_column)
        
        self.logger.debug(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥: {len(ts_df)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
        
        return ts_df
    
    def _resample_to_regular_grid(
        self, 
        df: pd.DataFrame, 
        time_column: str, 
        value_column: str,
        freq: str = '1H'
    ) -> pd.DataFrame:
        """–†–µ—Å–µ–º–ø–ª–∏–Ω–≥ –∫ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Å–µ—Ç–∫–µ"""
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω–¥–µ–∫—Å
        df_resampled = df.set_index(time_column)
        
        # –†–µ—Å–µ–º–ø–ª–∏–Ω–≥ —Å —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ–º –∑–Ω–∞—á–µ–Ω–∏–π
        df_resampled = df_resampled.resample(freq)[value_column].mean()
        
        # –ò–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        df_resampled = df_resampled.interpolate(method='linear')
        
        # –£–±–∏—Ä–∞–µ–º NaN –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
        df_resampled = df_resampled.dropna()
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º DataFrame
        result_df = df_resampled.reset_index()
        result_df.columns = [time_column, value_column]
        
        return result_df
    
    def detect_and_handle_outliers(
        self, 
        df: pd.DataFrame, 
        value_column: str,
        method: str = 'iqr',
        multiplier: float = 1.5
    ) -> pd.DataFrame:
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            value_column: –ö–æ–ª–æ–Ω–∫–∞ —Å–æ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            method: –ú–µ—Ç–æ–¥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è ('iqr', 'zscore')
            multiplier: –ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –ø–æ—Ä–æ–≥–∞
            
        Returns:
            DataFrame —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –≤—ã–±—Ä–æ—Å–∞–º–∏
        """
        result_df = df.copy()
        values = result_df[value_column]
        
        if method == 'iqr':
            Q1 = values.quantile(0.25)
            Q3 = values.quantile(0.75)
            IQR = Q3 - Q1
            
            lower_bound = Q1 - multiplier * IQR
            upper_bound = Q3 + multiplier * IQR
            
            outliers_mask = (values < lower_bound) | (values > upper_bound)
            
        elif method == 'zscore':
            z_scores = np.abs((values - values.mean()) / values.std())
            outliers_mask = z_scores > multiplier
            
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤: {method}")
        
        if outliers_mask.any():
            n_outliers = outliers_mask.sum()
            self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {n_outliers} –≤—ã–±—Ä–æ—Å–æ–≤, –∑–∞–º–µ–Ω—è–µ–º –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–µ–π")
            
            # –ó–∞–º–µ–Ω—è–µ–º –≤—ã–±—Ä–æ—Å—ã –Ω–∞ NaN –∏ –∏–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ–º
            result_df.loc[outliers_mask, value_column] = np.nan
            result_df[value_column] = result_df[value_column].interpolate(method='linear')
        
        return result_df
    
    def check_stationarity(self, series: pd.Series) -> Dict:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ —Å –ø–æ–º–æ—â—å—é —Ç–µ—Å—Ç–∞ –î–∏–∫–∏-–§—É–ª–ª–µ—Ä–∞
        
        Args:
            series: –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏
        """
        # –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è statsmodels
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            
            result = adfuller(series.dropna())
            
        adf_stat, p_value, used_lag, n_obs, critical_values, ic_best = result
        
        stationarity_result = {
            'adf_statistic': adf_stat,
            'p_value': p_value,
            'used_lags': used_lag,
            'n_observations': n_obs,
            'critical_values': critical_values,
            'is_stationary': p_value < 0.05  # 5% —É—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
        }
        
        self.logger.debug(
            f"–¢–µ—Å—Ç —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏: ADF={adf_stat:.4f}, p-value={p_value:.4f}, "
            f"—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω={stationarity_result['is_stationary']}"
        )
        
        return stationarity_result
    
    def make_stationary(self, series: pd.Series, max_diff: int = 2) -> Tuple[pd.Series, int]:
        """
        –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ä—è–¥–∞ –∫ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ–º—É –≤–∏–¥—É —á–µ—Ä–µ–∑ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ
        
        Args:
            series: –ò—Å—Ö–æ–¥–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥
            max_diff: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–π
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π —Ä—è–¥, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–π)
        """
        diff_series = series.copy()
        diff_order = 0
        
        for d in range(max_diff + 1):
            stationarity = self.check_stationarity(diff_series)
            
            if stationarity['is_stationary']:
                self.logger.debug(f"–†—è–¥ —Å—Ç–∞–ª —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–º –ø–æ—Å–ª–µ {d} –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–π")
                return diff_series, d

            if d < max_diff:
                diff_series = diff_series.diff().dropna()
                diff_order = d + 1
        
        self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ—Å—Ç–∏—á—å —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏ –∑–∞ {max_diff} –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–π")
        return diff_series, diff_order


class ARIMAForecaster:
    """–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é ARIMA –º–æ–¥–µ–ª–∏"""
    
    def __init__(self):
        self.logger = get_logger(f"{__name__}.{self.__class__.__name__}")
        self.model = None
        self.fitted_model = None
        self.preprocessor = TimeSeriesPreprocessor()
        
    def auto_arima_parameters(self, series: pd.Series) -> Tuple[int, int, int]:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ARIMA (p, d, q)
        
        Args:
            series: –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (p, d, q)
        """
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏—è (d)
        _, d = self.preprocessor.make_stationary(series)
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è p –∏ q
        # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –º–µ—Ç–æ–¥—ã
        max_lag = min(10, len(series) // 4)
        
        best_aic = float('inf')
        best_params = (1, d, 1)
        
        # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã p –∏ q
        for p in range(0, min(3, max_lag)):
            for q in range(0, min(3, max_lag)):
                try:
                    with warnings.catch_warnings():
                        warnings.simplefilter("ignore")
                        
                        temp_model = ARIMA(series, order=(p, d, q))
                        temp_fitted = temp_model.fit()
                        
                        if temp_fitted.aic < best_aic:
                            best_aic = temp_fitted.aic
                            best_params = (p, d, q)
                            
                except Exception:
                    continue
        
        self.logger.debug(f"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ARIMA: {best_params}, AIC={best_aic:.2f}")

        return best_params
    
    def fit(self, series: pd.Series, order: Optional[Tuple[int, int, int]] = None) -> Dict:
        """
        –û–±—É—á–µ–Ω–∏–µ ARIMA –º–æ–¥–µ–ª–∏
        
        Args:
            series: –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            order: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã ARIMA (p, d, q). –ï—Å–ª–∏ None, –ø–æ–¥–±–∏—Ä–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
        """
        if order is None:
            order = self.auto_arima_parameters(series)
        
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                
                self.model = ARIMA(series, order=order)
                self.fitted_model = self.model.fit()
                
            fit_results = {
                'order': order,
                'aic': self.fitted_model.aic,
                'bic': self.fitted_model.bic,
                'log_likelihood': self.fitted_model.llf,
                'success': True
            }
            
            self.logger.info(
                f"ARIMA{order} –æ–±—É—á–µ–Ω–∞: AIC={fit_results['aic']:.2f}, "
                f"BIC={fit_results['bic']:.2f}"
            )
            
            return fit_results
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è ARIMA: {e}")
            return {'success': False, 'error': str(e)}
    
    def forecast(self, steps: int) -> Dict:
        """
        –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ N —à–∞–≥–æ–≤ –≤–ø–µ—Ä–µ–¥
        
        Args:
            steps: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∞
        """
        if self.fitted_model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
        
        try:
            forecast_result = self.fitted_model.forecast(steps=steps)
            confidence_intervals = self.fitted_model.get_forecast(steps=steps).conf_int()
            
            forecast_data = {
                'forecast': forecast_result.tolist(),
                'lower_ci': confidence_intervals.iloc[:, 0].tolist(),
                'upper_ci': confidence_intervals.iloc[:, 1].tolist(),
                'steps': steps,
                'success': True
            }
            
            self.logger.debug(f"ARIMA –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {steps} —à–∞–≥–æ–≤: {forecast_result.mean():.4f}")
            
            return forecast_data
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è ARIMA: {e}")
            return {'success': False, 'error': str(e)}


class ProphetForecaster:
    """–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é Prophet"""
    
    def __init__(self):
        self.logger = get_logger(f"{__name__}.{self.__class__.__name__}")
        self.model = None
        
    def fit(self, df: pd.DataFrame, time_column: str = 'ds', value_column: str = 'y') -> Dict:
        """
        –û–±—É—á–µ–Ω–∏–µ Prophet –º–æ–¥–µ–ª–∏
        
        Args:
            df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'ds' (–≤—Ä–µ–º—è) –∏ 'y' (–∑–Ω–∞—á–µ–Ω–∏—è)
            time_column: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤—Ä–µ–º–µ–Ω–∏
            value_column: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –∑–Ω–∞—á–µ–Ω–∏–π
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
        """
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è Prophet
        prophet_df = df[[time_column, value_column]].copy()
        prophet_df.columns = ['ds', 'y']
        
        try:
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Prophet
            self.model = Prophet(
                daily_seasonality=True,
                weekly_seasonality=True,
                yearly_seasonality=False,  # –û—Ç–∫–ª—é—á–∞–µ–º –≥–æ–¥–æ–≤—É—é —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ä—è–¥–æ–≤
                changepoint_prior_scale=0.05,  # –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º —Ç—Ä–µ–Ω–¥–æ–≤
                seasonality_prior_scale=10,    # –°–∏–ª–∞ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏
                interval_width=0.95,           # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª 95%
                uncertainty_samples=1000
            )
            
            # –ü–æ–¥–∞–≤–ª—è–µ–º –≤—ã–≤–æ–¥ Prophet
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                self.model.fit(prophet_df)
            
            fit_results = {
                'n_observations': len(prophet_df),
                'trend_changepoints': len(self.model.changepoints),
                'success': True
            }
            
            self.logger.info(
                f"Prophet –æ–±—É—á–µ–Ω –Ω–∞ {fit_results['n_observations']} –Ω–∞–±–ª—é–¥–µ–Ω–∏—è—Ö, "
                f"—Ç–æ—á–µ–∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞: {fit_results['trend_changepoints']}"
            )
            
            return fit_results
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è Prophet: {e}")
            return {'success': False, 'error': str(e)}
    
    def forecast(self, periods: int, freq: str = 'H') -> Dict:
        """
        –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é Prophet
        
        Args:
            periods: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
            freq: –ß–∞—Å—Ç–æ—Ç–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞ ('H' - —á–∞—Å—ã, 'D' - –¥–Ω–∏)
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∞
        """
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
        
        try:
            # –°–æ–∑–¥–∞–µ–º –±—É–¥—É—â–∏–µ –¥–∞—Ç—ã
            future = self.model.make_future_dataframe(periods=periods, freq=freq)
            
            # –î–µ–ª–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                forecast = self.model.predict(future)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (—Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –ø–µ—Ä–∏–æ–¥—ã)
            forecast_data = forecast.tail(periods)
            
            result = {
                'forecast': forecast_data['yhat'].tolist(),
                'lower_ci': forecast_data['yhat_lower'].tolist(),
                'upper_ci': forecast_data['yhat_upper'].tolist(),
                'trend': forecast_data['trend'].tolist(),
                'seasonal': forecast_data.get('seasonal', [0] * periods).tolist(),
                'dates': forecast_data['ds'].dt.strftime('%Y-%m-%d %H:%M:%S').tolist(),
                'periods': periods,
                'success': True
            }
            
            self.logger.debug(
                f"Prophet –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {periods} –ø–µ—Ä–∏–æ–¥–æ–≤: "
                f"—Å—Ä–µ–¥–Ω–µ–µ={np.mean(result['forecast']):.4f}"
            )
            
            return result
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑ÔøΩÔøΩ—Ä–æ–≤–∞–Ω–∏—è Prophet: {e}")
            return {'success': False, 'error': str(e)}


class AnomalyProbabilityCalculator:
    """–†–∞—Å—á–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∞–Ω–æ–º–∞–ª–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤"""

    def __init__(self):
        self.logger = get_logger(f"{__name__}.{self.__class__.__name__}")

    def calculate_threshold_exceedance_probability(
        self,
        forecast_values: List[float],
        confidence_intervals: Tuple[List[float], List[float]],
        threshold: float,
        historical_std: float
    ) -> Dict:
        """
        –†–∞—Å—á–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ø–æ—Ä–æ–≥–∞

        Args:
            forecast_values: –ü—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            confidence_intervals: –ù–∏–∂–Ω–∏–µ –∏ –≤–µ—Ä—Ö–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
            threshold: –ü–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –∞–Ω–æ–º–∞–ª–∏–∏
            historical_std: –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞—Å—á–µ—Ç–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        """
        lower_ci, upper_ci = confidence_intervals

        probabilities = []
        exceedance_flags = []

        for i, (forecast, lower, upper) in enumerate(zip(forecast_values, lower_ci, upper_ci)):
            # –ú–µ—Ç–æ–¥ 1: –ü—Ä–æ—Å—Ç–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø–æ—Ä–æ–≥–æ–º
            exceeds_threshold = forecast > threshold

            # –ú–µ—Ç–æ–¥ 2: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
            # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∞
            forecast_std = (upper - lower) / (2 * 1.96)  # 95% –∏–Ω—Ç–µ—Ä–≤–∞–ª -> std

            if forecast_std > 0:
                # Z-score –¥–ª—è –ø–æ—Ä–æ–≥–∞
                z_score = (threshold - forecast) / forecast_std
                # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è = 1 - CDF(z_score)
                from scipy import stats
                prob_exceed = 1 - stats.norm.cdf(z_score)
            else:
                prob_exceed = 1.0 if exceeds_threshold else 0.0

            probabilities.append(prob_exceed)
            exceedance_flags.append(exceeds_threshold)

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        max_probability = max(probabilities) if probabilities else 0.0
        mean_probability = np.mean(probabilities) if probabilities else 0.0
        any_exceedance = any(exceedance_flags)

        result = {
            'step_probabilities': probabilities,
            'step_exceedance': exceedance_flags,
            'max_probability': max_probability,
            'mean_probability': mean_probability,
            'any_exceedance': any_exceedance,
            'threshold': threshold,
            'forecast_horizon': len(forecast_values)
        }

        self.logger.debug(
            f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∞–Ω–æ–º–∞–ª–∏–∏: –º–∞–∫—Å={max_probability:.3f}, "
            f"—Å—Ä–µ–¥–Ω—è—è={mean_probability:.3f}, –ø—Ä–µ–≤—ã—à–µ–Ω–∏–π={sum(exceedance_flags)}"
        )

        return result

    def adaptive_threshold_calculation(
        self,
        historical_values: List[float],
        method: str = 'statistical',
        multiplier: float = DEFAULT_ANOMALY_THRESHOLD
    ) -> float:
        """
        –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ä–∞—Å—á–µ—Ç –ø–æ—Ä–æ–≥–∞ –∞–Ω–æ–º–∞–ª–∏–∏

        Args:
            historical_values: –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
            method: –ú–µ—Ç–æ–¥ —Ä–∞—Å—á–µ—Ç–∞ ('statistical', 'quantile')
            multiplier: –ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –ø–æ—Ä–æ–≥–∞

        Returns:
            –ü–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        """
        values = np.array(historical_values)

        if method == 'statistical':
            # –°—Ä–µ–¥–Ω–µ–µ + N —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π
            mean_val = np.mean(values)
            std_val = np.std(values)
            threshold = mean_val + multiplier * std_val

        elif method == 'quantile':
            # –ü—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 95%)
            quantile = min(0.99, 0.5 + multiplier * 0.3)  # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –∫–≤–∞–Ω—Ç–∏–ª—å
            threshold = np.quantile(values, quantile)

        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥ —Ä–∞—Å—á–µ—Ç–∞ –ø–æ—Ä–æ–≥–∞: {method}")

        self.logger.debug(f"–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ ({method}): {threshold:.4f}")

        return threshold


class MotorRMSForecaster:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è RMS —Ç–æ–∫–æ–≤ –¥–≤–∏–≥–∞—Ç–µ–ª—è"""
    
    def __init__(self):
        self.logger = get_logger(f"{__name__}.{self.__class__.__name__}")
        self.preprocessor = TimeSeriesPreprocessor()
        self.probability_calculator = AnomalyProbabilityCalculator()
        
    async def load_rms_time_series(
        self,
        equipment_id: UUID,
        phase: str,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None,
        limit: Optional[int] = None
    ) -> pd.DataFrame:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ RMS –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ñ–∞–∑—ã
        
        Args:
            equipment_id: ID –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
            phase: –§–∞–∑–∞ ('a', 'b', 'c')
            start_time: –ù–∞—á–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è
            end_time: –ö–æ–Ω–µ—á–Ω–æ–µ –≤—Ä–µ–º—è
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
            
        Returns:
            DataFrame —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º —Ä—è–¥–æ–º RMS
        """
        phase_column_map = {'a': 'rms_a', 'b': 'rms_b', 'c': 'rms_c'}

        if phase not in phase_column_map:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ñ–∞–∑–∞: {phase}")

        rms_column = phase_column_map[phase]

        async with get_async_session() as session:
            # –°—Ç—Ä–æ–∏–º –∑–∞–ø—Ä–æ—Å
            query = (
                select(Feature.window_start, getattr(Feature, rms_column))
                .join(RawSignal)
                .where(
                    and_(
                        RawSignal.equipment_id == equipment_id,
                        getattr(Feature, rms_column).is_not(None)
                    )
                )
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
            if start_time:
                query = query.where(Feature.window_start >= start_time)
            if end_time:
                query = query.where(Feature.window_start <= end_time)

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
            query = query.order_by(Feature.window_start)

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            if limit:
                query = query.limit(limit)

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
            result = await session.execute(query)
            rows = result.fetchall()
            
            if len(rows) < MIN_OBSERVATIONS:
                raise InsufficientDataError(
                    f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–∞–∑—ã {phase}: {len(rows)} < {MIN_OBSERVATIONS}"
                )
            
            # –°–æ–∑–¥–∞–µ–º DataFrame
            df = pd.DataFrame(rows, columns=['timestamp', 'rms_value'])
            
            self.logger.info(
                f"–ó–∞–≥—Ä—É–∂–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–ª—è —Ñ–∞–∑—ã {phase}: {len(df)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π "
                f"—Å {df['timestamp'].min()} –ø–æ {df['timestamp'].max()}"
            )
            
            return df
    
    async def forecast_phase_rms(
        self,
        equipment_id: UUID,
        phase: str,
        forecast_steps: int = DEFAULT_FORECAST_STEPS,
        model_type: str = 'auto',
        anomaly_threshold_method: str = 'statistical',
        threshold_multiplier: float = DEFAULT_ANOMALY_THRESHOLD
    ) -> Dict:
        """
        –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ RMS –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ñ–∞–∑—ã
        
        Args:
            equipment_id: ID –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
            phase: –§–∞–∑–∞ ('a', 'b', 'c')
            forecast_steps: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∞
            model_type: –¢–∏–ø –º–æ–¥–µ–ª–∏ ('arima', 'prophet', 'auto')
            anomaly_threshold_method: –ú–µ—Ç–æ–¥ —Ä–∞—Å—á–µ—Ç–∞ –ø–æ—Ä–æ–≥–∞ –∞–Ω–æ–º–∞–ª–∏–∏
            threshold_multiplier: –ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –ø–æ—Ä–æ–≥–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            df = await self.load_rms_time_series(equipment_id, phase)
            
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
            df_clean = self.preprocessor.prepare_time_series(df, 'rms_value', 'timestamp')
            df_clean = self.preprocessor.detect_and_handle_outliers(df_clean, 'rms_value')

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥
            threshold = self.probability_calculator.adaptive_threshold_calculation(
                df_clean['rms_value'].tolist(),
                method=anomaly_threshold_method,
                multiplier=threshold_multiplier
            )

            # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å
            forecast_results = {}

            if model_type in ['arima', 'auto']:
                # ARIMA –ø—Ä–æ–≥–Ω–æ–∑
                arima_forecaster = ARIMAForecaster()
                arima_fit = arima_forecaster.fit(df_clean['rms_value'])

                if arima_fit['success']:
                    arima_forecast = arima_forecaster.forecast(forecast_steps)
                    if arima_forecast['success']:
                        forecast_results['arima'] = arima_forecast

            if model_type in ['prophet', 'auto']:
                # Prophet –ø—Ä–æ–≥–Ω–æ–∑
                prophet_forecaster = ProphetForecaster()
                prophet_df = df_clean.rename(columns={'timestamp': 'ds', 'rms_value': 'y'})
                prophet_fit = prophet_forecaster.fit(prophet_df)

                if prophet_fit['success']:
                    prophet_forecast = prophet_forecaster.forecast(forecast_steps)
                    if prophet_forecast['success']:
                        forecast_results['prophet'] = prophet_forecast

            # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π –ø—Ä–æ–≥–Ω–æ–∑ –∏–ª–∏ –∫–æ–º–±–∏–Ω–∏—Ä—É–µ–º
            if model_type == 'auto':
                final_forecast = self._select_best_forecast(forecast_results)
            else:
                final_forecast = forecast_results.get(model_type, {})
            
            if not final_forecast or not final_forecast.get('success'):
                raise ForecastingError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è —Ñ–∞–∑—ã {phase}")
            
            # –†–∞—Å—á–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∞–Ω–æ–º–∞–ª–∏–π
            anomaly_probs = self.probability_calculator.calculate_threshold_exceedance_probability(
                final_forecast['forecast'],
                (final_forecast['lower_ci'], final_forecast['upper_ci']),
                threshold,
                df_clean['rms_value'].std()
            )

            # –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = {
                'equipment_id': str(equipment_id),
                'phase': phase,
                'forecast': final_forecast,
                'anomaly_analysis': anomaly_probs,
                'historical_stats': {
                    'mean': float(df_clean['rms_value'].mean()),
                    'std': float(df_clean['rms_value'].std()),
                    'min': float(df_clean['rms_value'].min()),
                    'max': float(df_clean['rms_value'].max()),
                    'count': len(df_clean)
                },
                'threshold': threshold,
                'model_used': model_type,
                'forecast_horizon': forecast_steps,
                'timestamp': datetime.now().isoformat()
            }
            
            self.logger.info(
                f"–ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è —Ñ–∞–∑—ã {phase}: –º–æ–¥–µ–ª—å={model_type}, "
                f"–ø–æ—Ä–æ–≥={threshold:.4f}, –º–∞–∫—Å.–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å={anomaly_probs['max_probability']:.3f}"
            )
            
            return result
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–∑—ã {phase}: {e}")
            raise ForecastingError(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–∑—ã {phase}: {e}")
    
    def _select_best_forecast(self, forecast_results: Dict) -> Dict:
        """–í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö"""
        if 'prophet' in forecast_results and forecast_results['prophet']['success']:
            # Prophet –æ–±—ã—á–Ω–æ –ª—É—á—à–µ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö —Å —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å—é
            return forecast_results['prophet']
        elif 'arima' in forecast_results and forecast_results['arima']['success']:
            return forecast_results['arima']
        else:
            return {}
    
    async def forecast_all_phases(
        self,
        equipment_id: UUID,
        forecast_steps: int = DEFAULT_FORECAST_STEPS,
        **kwargs
    ) -> Dict:
        """
        –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö —Ñ–∞–∑ –¥–≤–∏–≥–∞—Ç–µ–ª—è
        
        Args:
            equipment_id: ID –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
            forecast_steps: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∞
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            –ü—Ä–æ–≥–Ω–æ–∑—ã –¥–ª—è –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ñ–∞–∑
        """
        phases = ['a', 'b', 'c']
        phase_names = {'a': 'R', 'b': 'S', 'c': 'T'}

        results = {
            'equipment_id': str(equipment_id),
            'phases': {},
            'summary': {
                'total_phases': 0,
                'successful_phases': 0,
                'failed_phases': 0,
                'max_anomaly_probability': 0.0,
                'critical_phases': []
            },
            'timestamp': datetime.now().isoformat()
        }
        
        for phase in phases:
            try:
                phase_result = await self.forecast_phase_rms(
                    equipment_id, phase, forecast_steps, **kwargs
                )
                
                results['phases'][phase] = phase_result
                results['summary']['successful_phases'] += 1

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                max_prob = phase_result['anomaly_analysis']['max_probability']
                if max_prob > results['summary']['max_anomaly_probability']:
                    results['summary']['max_anomaly_probability'] = max_prob
                
                # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–∑—ã (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∞–Ω–æ–º–∞–ª–∏–∏ > 70%)
                if max_prob > 0.7:
                    results['summary']['critical_phases'].append({
                        'phase': phase,
                        'phase_name': phase_names[phase],
                        'probability': max_prob
                    })

                self.logger.debug(f"–§–∞–∑–∞ {phase_names[phase]}: –ø—Ä–æ–≥–Ω–æ–∑ –≥–æ—Ç–æ–≤")
                
            except Exception as e:
                self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è —Ñ–∞–∑—ã {phase}: {e}")
                results['phases'][phase] = {
                    'error': str(e),
                    'success': False
                }
                results['summary']['failed_phases'] += 1
        
        results['summary']['total_phases'] = len(phases)
        
        self.logger.info(
            f"–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {results['summary']['successful_phases']}/{len(phases)} —Ñ–∞–∑, "
            f"–º–∞–∫—Å.–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∞–Ω–æ–º–∞–ª–∏–∏={results['summary']['max_anomaly_probability']:.3f}"
        )
        
        return results


# CLI —Ñ—É–Ω–∫—Ü–∏–∏

async def forecast_equipment_rms(
    equipment_id: str,
    forecast_steps: int = DEFAULT_FORECAST_STEPS,
    model_type: str = 'auto',
    phases: Optional[List[str]] = None
) -> Dict:
    """
    –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ RMS –¥–ª—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
    
    Args:
        equipment_id: ID –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
        forecast_steps: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∞
        model_type: –¢–∏–ø –º–æ–¥–µ–ª–∏
        phases: –°–ø–∏—Å–æ–∫ —Ñ–∞–∑ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ (–µ—Å–ª–∏ None, –≤—Å–µ —Ñ–∞–∑—ã)
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
    """
    forecaster = MotorRMSForecaster()
    equipment_uuid = UUID(equipment_id)
    
    if phases:
        # –ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–∞–∑
        results = {'phases': {}}
        
        for phase in phases:
            try:
                phase_result = await forecaster.forecast_phase_rms(
                    equipment_uuid, phase, forecast_steps, model_type
                )
                results['phases'][phase] = phase_result

            except Exception as e:
                results['phases'][phase] = {'error': str(e), 'success': False}

        return results
    else:
        # –ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –≤—Å–µ—Ö —Ñ–∞–∑
        return await forecaster.forecast_all_phases(equipment_uuid, forecast_steps)


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ RMS —Ç–æ–∫–æ–≤ –¥–≤–∏–≥–∞—Ç–µ–ª–µ–π")
    parser.add_argument("equipment_id", help="UUID –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è")
    parser.add_argument("--steps", type=int, default=DEFAULT_FORECAST_STEPS,
                       help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∞")
    parser.add_argument("--model", choices=['arima', 'prophet', 'auto'], default='auto',
                       help="–¢–∏–ø –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")
    parser.add_argument("--phases", nargs="+", choices=['a', 'b', 'c'],
                       help="–§–∞–∑—ã –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Å–µ)")
    parser.add_argument("--verbose", "-v", action="store_true", help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥")
    
    args = parser.parse_args()

    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    if args.verbose:
        import logging
        logging.getLogger().setLevel(logging.DEBUG)

    async def main():
        try:
            logger.info(f"–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ RMS –¥–ª—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è {args.equipment_id}")

            results = await forecast_equipment_rms(
                equipment_id=args.equipment_id,
                forecast_steps=args.steps,
                model_type=args.model,
                phases=args.phases
            )

            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if 'summary' in results:
                summary = results['summary']
                print(f"\nüìä –°–≤–æ–¥–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è:")
                print(f"  - –§–∞–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {summary['successful_phases']}/{summary['total_phases']}")
                print(f"  - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∞–Ω–æ–º–∞–ª–∏–∏: {summary['max_anomaly_probability']:.1%}")

                if summary['critical_phases']:
                    print(f"  - –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–∑—ã:")
                    for critical in summary['critical_phases']:
                        print(f"    ‚Ä¢ –§–∞–∑–∞ {critical['phase_name']}: {critical['probability']:.1%}")

            for phase, phase_result in results['phases'].items():
                if phase_result.get('success', True):
                    anomaly = phase_result['anomaly_analysis']
                    print(f"\nüîÆ –§–∞–∑–∞ {phase.upper()}:")
                    print(f"  - –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {args.steps} —à–∞–≥–æ–≤")
                    print(f"  - –ü–æ—Ä–æ–≥ –∞–Ω–æ–º–∞–ª–∏–∏: {phase_result['threshold']:.4f}")
                    print(f"  - –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è: {anomaly['max_probability']:.1%}")
                    if anomaly['any_exceedance']:
                        print(f"  - ‚ö†Ô∏è  –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ—Ç—Å—è –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞!")
                else:
                    print(f"\n‚ùå –§–∞–∑–∞ {phase.upper()}: {phase_result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")

            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return False
    
    import asyncio
    success = asyncio.run(main())
    exit(0 if success else 1)
