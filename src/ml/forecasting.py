# –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ RMS (ARIMA/Prophet, –ø–æ—Ä–æ–≥–∏, –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏)

import warnings
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Union
from uuid import UUID

import numpy as np
import pandas as pd
from prophet import Prophet
from sklearn.preprocessing import StandardScaler
from sqlalchemy import select, and_
from sqlalchemy.ext.asyncio import AsyncSession
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller

from src.config.settings import get_settings
from src.database.connection import get_async_session
from src.database.models import Feature, Equipment, RawSignal
from src.utils.logger import get_logger

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
settings = get_settings()
logger = get_logger(__name__)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
DEFAULT_FORECAST_STEPS = 24  # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 24 —à–∞–≥–∞ –≤–ø–µ—Ä–µ–¥
DEFAULT_ANOMALY_THRESHOLD = 1.5  # –ü–æ—Ä–æ–≥ –∞–Ω–æ–º–∞–ª–∏–∏ (–≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è—Ö)
MIN_OBSERVATIONS = 50  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
SEASONALITY_PERIOD = 24  # –ü–µ—Ä–∏–æ–¥ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ (24 —á–∞—Å–∞)


class ForecastingError(Exception):
    # –ë–∞–∑–æ–≤–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
    pass


class InsufficientDataError(ForecastingError):
    # –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
    pass


# === MVP —Ñ—É–Ω–∫—Ü–∏—è forecast_rms —Å–æ–≥–ª–∞—Å–Ω–æ –∫–æ–Ω—Ç—Ä–∞–∫—Ç—É ===
async def forecast_rms(equipment_id: UUID, n_steps: int = 24, threshold_sigma: float = 2.0):
    # –£–ø—Ä–æ—â—ë–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ RMS (MVP)
    from sqlalchemy import select
    from src.database.connection import get_async_session
    from src.database.models import Feature, RawSignal

    async with get_async_session() as session:
        # Join Feature -> RawSignal. –í —Ç–µ—Å—Ç–æ–≤–æ–π —Å—Ä–µ–¥–µ –Ω–∞ SQLite UUID –º–æ–≥—É—Ç —Ö—Ä–∞–Ω–∏—Ç—å—Å—è –∫–∞–∫ TEXT.
        # –£–Ω–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –µ—Å–ª–∏ dialect == 'sqlite'.
        from sqlalchemy import cast, String
        if session.bind.dialect.name == 'sqlite':  # pragma: no cover - —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ –¥–ª—è —Ç–µ—Å—Ç–æ–≤ sqlite
            q = (select(Feature)
                 .join(RawSignal)
                 .where(cast(RawSignal.equipment_id, String) == str(equipment_id))
                 .order_by(Feature.window_start.asc()))
        else:
            q = (select(Feature)
                 .join(RawSignal)
                 .where(RawSignal.equipment_id == equipment_id)
                 .order_by(Feature.window_start.asc()))
        res = await session.execute(q)
        feats = res.scalars().all()

    if len(feats) < MIN_OBSERVATIONS:
        raise InsufficientDataError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(feats)} < {MIN_OBSERVATIONS}")

    import pandas as pd
    rows = []
    for f in feats:
        values = [v for v in [f.rms_a, f.rms_b, f.rms_c] if v is not None]
        if not values:
            continue
        rows.append({
            'ts': f.window_start,
            'rms_mean': float(np.mean(values))
        })
    df = pd.DataFrame(rows)
    if df.empty or len(df) < MIN_OBSERVATIONS:
        raise InsufficientDataError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö RMS –∑–Ω–∞—á–µ–Ω–∏–π")

    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ —á–∞—Å—É
    df['ts_hour'] = pd.to_datetime(df['ts']).dt.floor('h')
    hourly = df.groupby('ts_hour')['rms_mean'].mean().reset_index().rename(columns={'ts_hour':'ds','rms_mean':'y'})

    series = hourly['y']
    mu = series.mean()
    sigma = series.std(ddof=0) or 1e-6
    threshold = mu + threshold_sigma * sigma

    forecast_values = []
    future_index = []
    try:
        from prophet import Prophet  # type: ignore
        m = Prophet(daily_seasonality=True, weekly_seasonality=False, yearly_seasonality=False)
        m.fit(hourly)
        future = m.make_future_dataframe(periods=n_steps, freq='h', include_history=False)
        fc = m.predict(future)
        forecast_values = fc['yhat'].tolist()
        future_index = future['ds'].tolist()
    except Exception:
        # Fallback: –ø—Ä–æ—Å—Ç–æ–µ —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–∫–Ω–∞
        window = min(12, len(series))
        last_ma = series.rolling(window).mean().iloc[-1]
        trend = (series.iloc[-1] - series.iloc[-window]) / max(window-1,1)
        for i in range(1, n_steps+1):
            forecast_values.append(float(last_ma + trend * i))
        import pandas as pd
        last_ts = hourly['ds'].iloc[-1]
        future_index = [last_ts + pd.Timedelta(hours=i) for i in range(1, n_steps+1)]

    over = [v for v in forecast_values if v > threshold]
    probability_over = len(over)/len(forecast_values) if forecast_values else 0.0

    return {
        'equipment_id': str(equipment_id),
        'history_points': len(series),
        'threshold': threshold,
        'forecast': [
            {'timestamp': ts.isoformat(), 'rms': float(v), 'over_threshold': v > threshold}
            for ts, v in zip(future_index, forecast_values)
        ],
        'probability_over_threshold': probability_over,
        'model': 'Prophet' if 'Prophet' in globals() and 'm' in locals() else 'FallbackMA'
    }


class TimeSeriesPreprocessor:
    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
    
    def __init__(self):
        self.logger = get_logger(f"{__name__}.{self.__class__.__name__}")
        
    def prepare_time_series(
        self, 
        df: pd.DataFrame, 
        value_column: str,
        time_column: str = 'timestamp'
    ) -> pd.DataFrame:
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥
        # –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        ts_df = df.copy()
        
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        ts_df = ts_df.dropna(subset=[value_column])
        
        if len(ts_df) < MIN_OBSERVATIONS:
            raise InsufficientDataError(
                f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(ts_df)} < {MIN_OBSERVATIONS}"
            )
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        ts_df = ts_df.sort_values(time_column)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        duplicates = ts_df[time_column].duplicated()
        if duplicates.any():
            self.logger.warning(f"–ù–∞–π–¥–µ–Ω–æ {duplicates.sum()} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏, —É–¥–∞–ª—è–µ–º")
            ts_df = ts_df[~duplicates]
        
        # –†–µ—Å–µ–º–ø–ª–∏–Ω–≥ –∫ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–π —Å–µ—Ç–∫–µ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        ts_df = self._resample_to_regular_grid(ts_df, time_column, value_column)
        
        self.logger.debug(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥: {len(ts_df)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
        
        return ts_df
    
    def _resample_to_regular_grid(
        self, 
        df: pd.DataFrame, 
        time_column: str, 
        value_column: str,
        freq: str = '1h'
    ) -> pd.DataFrame:
        # –†–µ—Å–µ–º–ø–ª–∏–Ω–≥ –∫ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–π —Å–µ—Ç–∫–µ
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω–¥–µ–∫—Å
        df_resampled = df.set_index(time_column)
        
        # –†–µ—Å–µ–º–ø–ª–∏–Ω–≥ —Å —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ–º –∑–Ω–∞—á–µ–Ω–∏–π
        df_resampled = df_resampled.resample(freq)[value_column].mean()
        
        # –ò–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        df_resampled = df_resampled.interpolate(method='linear')
        
        # –£–±–∏—Ä–∞–µ–º NaN –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
        df_resampled = df_resampled.dropna()
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º DataFrame
        result_df = df_resampled.reset_index()
        result_df.columns = [time_column, value_column]
        
        return result_df
    
    def detect_and_handle_outliers(
        self, 
        df: pd.DataFrame, 
        value_column: str,
        method: str = 'iqr',
        multiplier: float = 1.5
    ) -> pd.DataFrame:
        # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤
        result_df = df.copy()
        values = result_df[value_column]
        
        if method == 'iqr':
            Q1 = values.quantile(0.25)
            Q3 = values.quantile(0.75)
            IQR = Q3 - Q1
            
            lower_bound = Q1 - multiplier * IQR
            upper_bound = Q3 + multiplier * IQR
            
            outliers_mask = (values < lower_bound) | (values > upper_bound)
            
        elif method == 'zscore':
            z_scores = np.abs((values - values.mean()) / values.std())
            outliers_mask = z_scores > multiplier
            
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤: {method}")
        
        if outliers_mask.any():
            n_outliers = outliers_mask.sum()
            self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {n_outliers} –≤—ã–±—Ä–æ—Å–æ–≤, –∑–∞–º–µ–Ω—è–µ–º –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–µ–π")
            
            # –ó–∞–º–µ–Ω—è–µ–º –≤—ã–±—Ä–æ—Å—ã –Ω–∞ NaN –∏ –∏–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ–º
            result_df.loc[outliers_mask, value_column] = np.nan
            result_df[value_column] = result_df[value_column].interpolate(method='linear')
        
        return result_df
    
    def check_stationarity(self, series: pd.Series) -> Dict:
        # –¢–µ—Å—Ç —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏ (ADF)
        # –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è statsmodels
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            
            result = adfuller(series.dropna())
            
        adf_stat, p_value, used_lag, n_obs, critical_values, ic_best = result
        
        stationarity_result = {
            'adf_statistic': adf_stat,
            'p_value': p_value,
            'used_lags': used_lag,
            'n_observations': n_obs,
            'critical_values': critical_values,
            # –Ø–≤–Ω–æ –ø—Ä–∏–≤–æ–¥–∏–º –∫ builtin bool –¥–ª—è —Ç–µ—Å—Ç–æ–≤ (adfuller –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç numpy.float64 -> —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–∞–µ—Ç numpy.bool_)
            'is_stationary': bool(p_value < 0.05)  # 5% —É—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
        }
        
        self.logger.debug(
            f"–¢–µ—Å—Ç —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏: ADF={adf_stat:.4f}, p-value={p_value:.4f}, "
            f"—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω={stationarity_result['is_stationary']}"
        )
        
        return stationarity_result
    
    def make_stationary(self, series: pd.Series, max_diff: int = 2) -> Tuple[pd.Series, int]:
        # –î–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏
        diff_series = series.copy()
        diff_order = 0
        
        for d in range(max_diff + 1):
            stationarity = self.check_stationarity(diff_series)
            
            if stationarity['is_stationary']:
                self.logger.debug(f"–†—è–¥ —Å—Ç–∞–ª —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–º –ø–æ—Å–ª–µ {d} –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–π")
                return diff_series, d

            if d < max_diff:
                diff_series = diff_series.diff().dropna()
                diff_order = d + 1
        
        self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ—Å—Ç–∏—á—å —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏ –∑–∞ {max_diff} –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–π")
        return diff_series, diff_order


class ARIMAForecaster:
    # –ü—Ä–æ–≥–Ω–æ–∑ ARIMA
    
    def __init__(self):
        self.logger = get_logger(f"{__name__}.{self.__class__.__name__}")
        self.model = None
        self.fitted_model = None
        self.preprocessor = TimeSeriesPreprocessor()
        
    def auto_arima_parameters(self, series: pd.Series) -> Tuple[int, int, int]:
        # –ê–≤—Ç–æ–ø–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ARIMA
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏—è (d)
        _, d = self.preprocessor.make_stationary(series)
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è p –∏ q
        # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –º–µ—Ç–æ–¥—ã
        max_lag = min(10, len(series) // 4)
        
        best_aic = float('inf')
        best_params = (1, d, 1)
        
        # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã p –∏ q
        for p in range(0, min(3, max_lag)):
            for q in range(0, min(3, max_lag)):
                try:
                    with warnings.catch_warnings():
                        warnings.simplefilter("ignore")
                        
                        temp_model = ARIMA(series, order=(p, d, q))
                        temp_fitted = temp_model.fit()
                        
                        if temp_fitted.aic < best_aic:
                            best_aic = temp_fitted.aic
                            best_params = (p, d, q)
                            
                except Exception:
                    continue
        
        self.logger.debug(f"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ARIMA: {best_params}, AIC={best_aic:.2f}")

        return best_params
    
    def fit(self, series: pd.Series, order: Optional[Tuple[int, int, int]] = None) -> Dict:
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ARIMA
        if len(series) < MIN_OBSERVATIONS:
            raise InsufficientDataError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ARIMA: {len(series)} < {MIN_OBSERVATIONS}")

        if order is None:
            order = self.auto_arima_parameters(series)
        
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                
                self.model = ARIMA(series, order=order)
                self.fitted_model = self.model.fit()
                
            fit_results = {
                'order': order,
                'aic': self.fitted_model.aic,
                'bic': self.fitted_model.bic,
                'log_likelihood': self.fitted_model.llf,
                'success': True
            }
            
            self.logger.info(
                f"ARIMA{order} –æ–±—É—á–µ–Ω–∞: AIC={fit_results['aic']:.2f}, "
                f"BIC={fit_results['bic']:.2f}"
            )
            
            return fit_results
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è ARIMA: {e}")
            return {'success': False, 'error': str(e)}
    
    def forecast(self, steps: int) -> Dict:
        # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ steps —à–∞–≥–æ–≤
        if self.fitted_model is None:
                raise ForecastingError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
        
        try:
            forecast_result = self.fitted_model.forecast(steps=steps)
            confidence_intervals = self.fitted_model.get_forecast(steps=steps).conf_int()
            
            forecast_data = {
                'forecast': forecast_result.tolist(),
                'lower_ci': confidence_intervals.iloc[:, 0].tolist(),
                'upper_ci': confidence_intervals.iloc[:, 1].tolist(),
                'steps': steps,
                'success': True
            }
            
            self.logger.debug(f"ARIMA –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {steps} —à–∞–≥–æ–≤: {forecast_result.mean():.4f}")
            
            return forecast_data
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è ARIMA: {e}")
            return {'success': False, 'error': str(e)}

    # Alias –¥–ª—è —Ç–µ—Å—Ç–æ–≤
    def auto_arima_params(self, series: pd.Series) -> Tuple[int, int, int]:  # pragma: no cover
        return self.auto_arima_parameters(series)


class ProphetForecaster:
    # –ü—Ä–æ–≥–Ω–æ–∑ Prophet
    
    def __init__(self):
        self.logger = get_logger(f"{__name__}.{self.__class__.__name__}")
        self.model = None
        
    def fit(self, df: pd.DataFrame, time_column: str = 'ds', value_column: str = 'y') -> Dict:
        # –û–±—É—á–µ–Ω–∏–µ Prophet
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è Prophet
        prophet_df = df[[time_column, value_column]].copy()
        prophet_df.columns = ['ds', 'y']
        
        if len(prophet_df) < MIN_OBSERVATIONS:
            raise InsufficientDataError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Prophet: {len(prophet_df)} < {MIN_OBSERVATIONS}")

        try:
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Prophet
            self.model = Prophet(
                daily_seasonality=True,
                weekly_seasonality=True,
                yearly_seasonality=False,  # –û—Ç–∫–ª—é—á–∞–µ–º –≥–æ–¥–æ–≤—É—é —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ä—è–¥–æ–≤
                changepoint_prior_scale=0.05,  # –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º —Ç—Ä–µ–Ω–¥–æ–≤
                seasonality_prior_scale=10,    # –°–∏–ª–∞ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏
                interval_width=0.95,           # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª 95%
                uncertainty_samples=1000
            )
            
            # –ü–æ–¥–∞–≤–ª—è–µ–º –≤—ã–≤–æ–¥ Prophet
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                self.model.fit(prophet_df)
            
            fit_results = {
                'n_observations': len(prophet_df),
                'trend_changepoints': len(self.model.changepoints),
                'model_type': 'prophet',
                'success': True
            }
            
            self.logger.info(
                f"Prophet –æ–±—É—á–µ–Ω –Ω–∞ {fit_results['n_observations']} –Ω–∞–±–ª—é–¥–µ–Ω–∏—è—Ö, "
                f"—Ç–æ—á–µ–∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞: {fit_results['trend_changepoints']}"
            )
            
            return fit_results
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è Prophet: {e}")
            return {'success': False, 'error': str(e)}
    
    def forecast(self, periods: int, freq: str = 'h') -> Dict:
        # –ü—Ä–æ–≥–Ω–æ–∑ Prophet
        if self.model is None:
                raise ForecastingError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
        
        try:
            # –°–æ–∑–¥–∞–µ–º –±—É–¥—É—â–∏–µ –¥–∞—Ç—ã
            future = self.model.make_future_dataframe(periods=periods, freq=freq)
            
            # –î–µ–ª–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                forecast = self.model.predict(future)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (—Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –ø–µ—Ä–∏–æ–¥—ã)
            forecast_data = forecast.tail(periods)
            
            seasonal_values = []
            if 'seasonal' in forecast_data.columns:
                col_val = forecast_data['seasonal']
                seasonal_values = col_val.tolist() if hasattr(col_val, 'tolist') else list(col_val)
            else:
                seasonal_values = [0.0] * periods
            result = {
                'forecast': forecast_data['yhat'].tolist(),
                'lower_ci': forecast_data['yhat_lower'].tolist(),
                'upper_ci': forecast_data['yhat_upper'].tolist(),
                'trend': forecast_data['trend'].tolist(),
                'seasonal': seasonal_values,
                'dates': forecast_data['ds'].dt.strftime('%Y-%m-%d %H:%M:%S').tolist(),
                'periods': periods,
                'success': True
            }
            
            self.logger.debug(
                f"Prophet –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {periods} –ø–µ—Ä–∏–æ–¥–æ–≤: "
                f"—Å—Ä–µ–¥–Ω–µ–µ={np.mean(result['forecast']):.4f}"
            )
            
            return result
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è Prophet: {e}")
            return {'success': False, 'error': str(e)}


class AnomalyProbabilityCalculator:
    # –†–∞—Å—á–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∞–Ω–æ–º–∞–ª–∏–π

    def __init__(self):
        self.logger = get_logger(f"{__name__}.{self.__class__.__name__}")

    def calculate_threshold_exceedance_probability(
        self,
        forecast_values: List[float],
        confidence_intervals: Tuple[List[float], List[float]],
        threshold: float,
        historical_std: float
    ) -> Dict:
        # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ø–æ—Ä–æ–≥–∞
        lower_ci, upper_ci = confidence_intervals

        probabilities = []
        exceedance_flags = []

        for i, (forecast, lower, upper) in enumerate(zip(forecast_values, lower_ci, upper_ci)):
            # –ú–µ—Ç–æ–¥ 1: –ü—Ä–æ—Å—Ç–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø–æ—Ä–æ–≥–æ–º
            exceeds_threshold = forecast > threshold

            # –ú–µ—Ç–æ–¥ 2: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
            # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∞
            forecast_std = (upper - lower) / (2 * 1.96)  # 95% –∏–Ω—Ç–µ—Ä–≤–∞–ª -> std

            if forecast_std > 0:
                # Z-score –¥–ª—è –ø–æ—Ä–æ–≥–∞
                z_score = (threshold - forecast) / forecast_std
                # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è = 1 - CDF(z_score)
                from scipy import stats
                prob_exceed = 1 - stats.norm.cdf(z_score)
            else:
                prob_exceed = 1.0 if exceeds_threshold else 0.0

            probabilities.append(prob_exceed)
            exceedance_flags.append(exceeds_threshold)

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        max_probability = max(probabilities) if probabilities else 0.0
        mean_probability = np.mean(probabilities) if probabilities else 0.0
        any_exceedance = any(exceedance_flags)

        result = {
            'step_probabilities': probabilities,
            'step_exceedance': exceedance_flags,
            'max_probability': max_probability,
            'mean_probability': mean_probability,
            'any_exceedance': any_exceedance,
            'threshold': threshold,
            'forecast_horizon': len(forecast_values)
        }

        self.logger.debug(
            f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∞–Ω–æ–º–∞–ª–∏–∏: –º–∞–∫—Å={max_probability:.3f}, "
            f"—Å—Ä–µ–¥–Ω—è—è={mean_probability:.3f}, –ø—Ä–µ–≤—ã—à–µ–Ω–∏–π={sum(exceedance_flags)}"
        )

        return result

    def adaptive_threshold_calculation(
        self,
        historical_values: List[float],
        method: str = 'statistical',
        multiplier: float = DEFAULT_ANOMALY_THRESHOLD
    ) -> float:
        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ä–∞—Å—á–µ—Ç –ø–æ—Ä–æ–≥–∞
        values = np.array(historical_values)

        if method == 'statistical':
            # –°—Ä–µ–¥–Ω–µ–µ + N —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π
            mean_val = np.mean(values)
            std_val = np.std(values)
            threshold = mean_val + multiplier * std_val

        elif method == 'quantile':
            # –ü—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 95%)
            quantile = min(0.99, 0.5 + multiplier * 0.3)  # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –∫–≤–∞–Ω—Ç–∏–ª—å
            threshold = np.quantile(values, quantile)

        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥ —Ä–∞—Å—á–µ—Ç–∞ –ø–æ—Ä–æ–≥–∞: {method}")

        self.logger.debug(f"–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ ({method}): {threshold:.4f}")

        return threshold


class MotorRMSForecaster:
    # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ RMS —Ç–æ–∫–æ–≤ –¥–≤–∏–≥–∞—Ç–µ–ª—è
    
    def __init__(self):
        self.logger = get_logger(f"{__name__}.{self.__class__.__name__}")
        self.preprocessor = TimeSeriesPreprocessor()
        self.probability_calculator = AnomalyProbabilityCalculator()
        
    async def load_rms_time_series(
        self,
        equipment_id: UUID,
        phase: str,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None,
        limit: Optional[int] = None,
        session: Optional[AsyncSession] = None,
    ) -> pd.DataFrame:
        # –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ RMS –ø–æ —Ñ–∞–∑–µ
        phase_column_map = {'a': 'rms_a', 'b': 'rms_b', 'c': 'rms_c'}

        if phase not in phase_column_map:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ñ–∞–∑–∞: {phase}")

        rms_column = phase_column_map[phase]

        # –ü–æ–∑–≤–æ–ª—è–µ–º –∏–Ω—ä–µ–∫—Ü–∏—é –≤–Ω–µ—à–Ω–µ–π —Å–µ—Å—Å–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–æ–≤ / –±–∞—Ç—á–µ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
        if session is None:
            async with get_async_session() as _session:
                rows = await self._fetch_rms_rows(_session, equipment_id, rms_column, start_time, end_time, limit)
        else:
            rows = await self._fetch_rms_rows(session, equipment_id, rms_column, start_time, end_time, limit)
            
            if len(rows) < MIN_OBSERVATIONS:
                raise InsufficientDataError(
                    f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–∞–∑—ã {phase}: {len(rows)} < {MIN_OBSERVATIONS}"
                )
            
            # –°–æ–∑–¥–∞–µ–º DataFrame
            df = pd.DataFrame(rows, columns=['timestamp', 'rms_value'])
            
            self.logger.info(
                f"–ó–∞–≥—Ä—É–∂–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–ª—è —Ñ–∞–∑—ã {phase}: {len(df)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π "
                f"—Å {df['timestamp'].min()} –ø–æ {df['timestamp'].max()}"
            )
            
            return df

    async def _fetch_rms_rows(
        self,
        session: AsyncSession,
        equipment_id: UUID,
        rms_column: str,
        start_time: Optional[datetime],
        end_time: Optional[datetime],
        limit: Optional[int]
    ) -> List[Tuple[datetime, float]]:
        query = (
            select(Feature.window_start, getattr(Feature, rms_column))
            .join(RawSignal)
            .where(
                and_(
                    RawSignal.equipment_id == equipment_id,
                    getattr(Feature, rms_column).is_not(None)
                )
            )
        )
        if start_time:
            query = query.where(Feature.window_start >= start_time)
        if end_time:
            query = query.where(Feature.window_start <= end_time)
        query = query.order_by(Feature.window_start)
        if limit:
            query = query.limit(limit)
        result = await session.execute(query)
        return result.fetchall()
    
    async def forecast_phase_rms(
        self,
        equipment_id: UUID,
        phase: str,
        forecast_steps: int = DEFAULT_FORECAST_STEPS,
        model_type: str = 'auto',
        anomaly_threshold_method: str = 'statistical',
        threshold_multiplier: float = DEFAULT_ANOMALY_THRESHOLD,
        preloaded_df: Optional[pd.DataFrame] = None,
        session: Optional[AsyncSession] = None,
    ) -> Dict:
        # –ü—Ä–æ–≥–Ω–æ–∑ RMS –¥–ª—è —Ñ–∞–∑—ã
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π DataFrame –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω)
            if preloaded_df is not None:
                df = preloaded_df
            else:
                df = await self.load_rms_time_series(equipment_id, phase, session=session)
            
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
            df_clean = self.preprocessor.prepare_time_series(df, 'rms_value', 'timestamp')
            df_clean = self.preprocessor.detect_and_handle_outliers(df_clean, 'rms_value')

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥
            threshold = self.probability_calculator.adaptive_threshold_calculation(
                df_clean['rms_value'].tolist(),
                method=anomaly_threshold_method,
                multiplier=threshold_multiplier
            )

            # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å
            forecast_results = {}

            if model_type in ['arima', 'auto']:
                # ARIMA –ø—Ä–æ–≥–Ω–æ–∑
                arima_forecaster = ARIMAForecaster()
                arima_fit = arima_forecaster.fit(df_clean['rms_value'])

                if arima_fit['success']:
                    arima_forecast = arima_forecaster.forecast(forecast_steps)
                    if arima_forecast['success']:
                        forecast_results['arima'] = arima_forecast

            if model_type in ['prophet', 'auto']:
                # Prophet –ø—Ä–æ–≥–Ω–æ–∑
                prophet_forecaster = ProphetForecaster()
                prophet_df = df_clean.rename(columns={'timestamp': 'ds', 'rms_value': 'y'})
                prophet_fit = prophet_forecaster.fit(prophet_df)

                if prophet_fit['success']:
                    prophet_forecast = prophet_forecaster.forecast(forecast_steps)
                    if prophet_forecast['success']:
                        forecast_results['prophet'] = prophet_forecast

            # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π –ø—Ä–æ–≥–Ω–æ–∑ –∏–ª–∏ –∫–æ–º–±–∏–Ω–∏—Ä—É–µ–º
            if model_type == 'auto':
                final_forecast = self._select_best_forecast(forecast_results)
            else:
                final_forecast = forecast_results.get(model_type, {})
            
            if not final_forecast or not final_forecast.get('success'):
                raise ForecastingError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è —Ñ–∞–∑—ã {phase}")
            
            # –†–∞—Å—á–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∞–Ω–æ–º–∞–ª–∏–π
            anomaly_probs = self.probability_calculator.calculate_threshold_exceedance_probability(
                final_forecast['forecast'],
                (final_forecast['lower_ci'], final_forecast['upper_ci']),
                threshold,
                df_clean['rms_value'].std()
            )

            # –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = {
                'equipment_id': str(equipment_id),
                'phase': phase,
                'forecast': final_forecast,
                'anomaly_analysis': anomaly_probs,
                'historical_stats': {
                    'mean': float(df_clean['rms_value'].mean()),
                    'std': float(df_clean['rms_value'].std()),
                    'min': float(df_clean['rms_value'].min()),
                    'max': float(df_clean['rms_value'].max()),
                    'count': len(df_clean)
                },
                'threshold': threshold,
                'model_used': model_type,
                'forecast_horizon': forecast_steps,
                'timestamp': datetime.now().isoformat()
            }
            
            self.logger.info(
                f"–ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è —Ñ–∞–∑—ã {phase}: –º–æ–¥–µ–ª—å={model_type}, "
                f"–ø–æ—Ä–æ–≥={threshold:.4f}, –º–∞–∫—Å.–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å={anomaly_probs['max_probability']:.3f}"
            )
            
            return result
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–∑—ã {phase}: {e}")
            raise ForecastingError(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–∑—ã {phase}: {e}")
    
    def _select_best_forecast(self, forecast_results: Dict) -> Dict:
        # –í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞
        if 'prophet' in forecast_results and forecast_results['prophet']['success']:
            # Prophet –æ–±—ã—á–Ω–æ –ª—É—á—à–µ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö —Å —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å—é
            return forecast_results['prophet']
        elif 'arima' in forecast_results and forecast_results['arima']['success']:
            return forecast_results['arima']
        else:
            return {}
    
    async def forecast_all_phases(
        self,
        equipment_id: UUID,
        forecast_steps: int = DEFAULT_FORECAST_STEPS,
        **kwargs
    ) -> Dict:
        # –ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –≤—Å–µ—Ö —Ñ–∞–∑
        phases = ['a', 'b', 'c']
        phase_names = {'a': 'R', 'b': 'S', 'c': 'T'}

        results = {
            'equipment_id': str(equipment_id),
            'phases': {},
            'summary': {
                'total_phases': 0,
                'successful_phases': 0,
                'failed_phases': 0,
                'max_anomaly_probability': 0.0,
                'critical_phases': []
            },
            'timestamp': datetime.now().isoformat()
        }
        
        for phase in phases:
            try:
                phase_result = await self.forecast_phase_rms(
                    equipment_id, phase, forecast_steps, **kwargs
                )
                
                results['phases'][phase] = phase_result
                results['summary']['successful_phases'] += 1

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                max_prob = phase_result['anomaly_analysis']['max_probability']
                if max_prob > results['summary']['max_anomaly_probability']:
                    results['summary']['max_anomaly_probability'] = max_prob
                
                # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–∑—ã (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∞–Ω–æ–º–∞–ª–∏–∏ > 70%)
                if max_prob > 0.7:
                    results['summary']['critical_phases'].append({
                        'phase': phase,
                        'phase_name': phase_names[phase],
                        'probability': max_prob
                    })

                self.logger.debug(f"–§–∞–∑–∞ {phase_names[phase]}: –ø—Ä–æ–≥–Ω–æ–∑ –≥–æ—Ç–æ–≤")
                
            except Exception as e:
                self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è —Ñ–∞–∑—ã {phase}: {e}")
                results['phases'][phase] = {
                    'error': str(e),
                    'success': False
                }
                results['summary']['failed_phases'] += 1
        
        results['summary']['total_phases'] = len(phases)
        
        self.logger.info(
            f"–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {results['summary']['successful_phases']}/{len(phases)} —Ñ–∞–∑, "
            f"–º–∞–∫—Å.–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∞–Ω–æ–º–∞–ª–∏–∏={results['summary']['max_anomaly_probability']:.3f}"
        )
        
        return results


# --- –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –∑–∞–¥–∞—á–∞–º–∏ worker ---
class RMSTrendForecaster:
    # –û–±—ë—Ä—Ç–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç MotorRMSForecaster)

    def __init__(self):
        self._impl = MotorRMSForecaster()

    # --- –ú–µ—Ç–æ–¥—ã —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏, –æ–∂–∏–¥–∞–µ–º—ã–µ —Ç–µ—Å—Ç–∞–º–∏ ---
    async def load_rms_data(self, equipment_id: UUID, phase: str, session: Optional[AsyncSession] = None):
        base = await self._impl.load_rms_time_series(equipment_id, phase, session=session)
        return base.rename(columns={'rms_value': f'rms_{phase}'})

    async def analyze_phase_trend(
        self,
        equipment_id: UUID,
        phase: str,
        session: Optional[AsyncSession] = None,
        forecast_steps: int = DEFAULT_FORECAST_STEPS
    ) -> Dict:
        raw = await self.load_rms_data(equipment_id, phase, session=session)
        internal_df = raw.rename(columns={f'rms_{phase}': 'rms_value'})
        internal = await self._impl.forecast_phase_rms(
            equipment_id,
            phase,
            forecast_steps,
            preloaded_df=internal_df,
            session=session,
        )
        return {
            'equipment_id': internal['equipment_id'],
            'phase': internal['phase'],
            'statistics': internal['historical_stats'],
            'forecasts': internal['forecast'],
            'anomaly': internal['anomaly_analysis'],
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–ª—é—á–∏ —á—Ç–æ–±—ã –Ω–µ —Ç–µ—Ä—è—Ç—å —Å–µ–º–∞–Ω—Ç–∏–∫—É
            'threshold': internal['threshold'],
            'model_used': internal['model_used'],
            'forecast_horizon': internal['forecast_horizon'],
        }

    def calculate_anomaly_probability(
        self,
        forecast_data: Dict,
        current_mean: float,
        current_std: float
    ) -> Dict:
        forecast = forecast_data.get('forecast', [])
        upper_ci = forecast_data.get('upper_ci', forecast)
        anomaly_probs = []
        threshold = current_mean + DEFAULT_ANOMALY_THRESHOLD * (current_std or 1e-6)
        for val, upper in zip(forecast, upper_ci):
            if upper > threshold:
                prob = min(1.0, max(0.0, (upper - threshold) / (abs(threshold) + 1e-6)))
            else:
                prob = 0.0
            anomaly_probs.append(prob)
        return {
            'anomaly_probabilities': anomaly_probs,
            'max_probability': max(anomaly_probs) if anomaly_probs else 0.0,
            'any_exceedance': any(p > 0 for p in anomaly_probs)
        }

    def _get_recommendation(self, probability: float) -> str:
        if probability >= 0.85:
            return "–ö–†–ò–¢–ò–ß–ï–°–ö–û–ï: –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ –ø—Ä–æ–≤–µ—Å—Ç–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É"
        if probability >= 0.7:
            return "–í–´–°–û–ö–ò–ô: –ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –≤–Ω–µ–ø–ª–∞–Ω–æ–≤—ã–π –æ—Å–º–æ—Ç—Ä"
        if probability >= 0.5:
            return "–°–†–ï–î–ù–ò–ô: —É—Å–∏–ª–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"
        if probability >= 0.25:
            return "–ù–ò–ó–ö–ò–ô: –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ"
        return "–ù–û–†–ú–ê–õ–¨–ù–û–ï —Å–æ—Å—Ç–æ—è–Ω–∏–µ"

    async def forecast_equipment_trends(
        self,
        equipment_id: UUID,
        session: Optional["AsyncSession"] = None,  # –ø–∞—Ä–∞–º–µ—Ç—Ä —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è —Å–∏–≥–Ω–∞—Ç—É—Ä—ã, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–ø—Ä—è–º—É—é
        phases: Optional[List[str]] = None,
        forecast_steps: int = DEFAULT_FORECAST_STEPS,
        **kwargs
    ) -> Dict:
        # MotorRMSForecaster —Å–∞–º –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ; –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –º–æ–∂–Ω–æ
        # —Ä–∞—Å—à–∏—Ä–∏—Ç—å, —á—Ç–æ–±—ã –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π session.
        result = await self._impl.forecast_all_phases(
            equipment_id=equipment_id,
            forecast_steps=forecast_steps,
        )
        # –î–æ–±–∞–≤–ª—è–µ–º —è–≤–Ω–æ–µ –ø–æ–ª–µ forecast_steps –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ downstream-–∫–æ–¥–∞
        result.setdefault('forecast_steps', forecast_steps)
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ñ–∞–∑ –µ—Å–ª–∏ –∑–∞–¥–∞–Ω —Å–ø–∏—Å–æ–∫
        if phases:
            result['phases'] = {k: v for k, v in result['phases'].items() if k in phases}
            result['summary']['total_phases'] = len(phases)
        return result


# CLI —Ñ—É–Ω–∫—Ü–∏–∏

async def forecast_equipment_rms(
    equipment_id: str,
    forecast_steps: int = DEFAULT_FORECAST_STEPS,
    model_type: str = 'auto',
    phases: Optional[List[str]] = None
) -> Dict:
    """
    –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ RMS –¥–ª—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
    
    Args:
        equipment_id: ID –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
        forecast_steps: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∞
        model_type: –¢–∏–ø –º–æ–¥–µ–ª–∏
        phases: –°–ø–∏—Å–æ–∫ —Ñ–∞–∑ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ (–µ—Å–ª–∏ None, –≤—Å–µ —Ñ–∞–∑—ã)
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
    """
    forecaster = MotorRMSForecaster()
    equipment_uuid = UUID(equipment_id)
    
    if phases:
        # –ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–∞–∑
        results = {'phases': {}}
        
        for phase in phases:
            try:
                phase_result = await forecaster.forecast_phase_rms(
                    equipment_uuid, phase, forecast_steps, model_type
                )
                results['phases'][phase] = phase_result

            except Exception as e:
                results['phases'][phase] = {'error': str(e), 'success': False}

        return results
    else:
        # –ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –≤—Å–µ—Ö —Ñ–∞–∑
        return await forecaster.forecast_all_phases(equipment_uuid, forecast_steps)


# === –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏, –æ–∂–∏–¥–∞–µ–º—ã–µ —Ç–µ—Å—Ç–∞–º–∏ (–æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å) ===
async def forecast_rms_trends(
    equipment_id: UUID,
    forecast_steps: int = DEFAULT_FORECAST_STEPS,
    phases: Optional[List[str]] = None,
    **kwargs
) -> Dict:
    # –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –ø—Ä–æ–≥–Ω–æ–∑ —Ç—Ä–µ–Ω–¥–æ–≤ RMS
    forecaster = RMSTrendForecaster()
    return await forecaster.forecast_equipment_trends(
        equipment_id=equipment_id,
        phases=phases,
        forecast_steps=forecast_steps,
        **kwargs
    )


async def get_anomaly_probability(
    equipment_id: UUID,
    forecast_steps: int = DEFAULT_FORECAST_STEPS,
    **kwargs
) -> float:
    # –ú–∞–∫—Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∞–Ω–æ–º–∞–ª–∏–∏ (–æ—à–∏–±–∫–∞ -> 0.0)
    try:
        result = await forecast_rms_trends(
            equipment_id=equipment_id,
            forecast_steps=forecast_steps,
            **kwargs
        )
        return float(result.get('summary', {}).get('max_anomaly_probability', 0.0))
    except Exception as e:  # pragma: no cover - –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–∞—è –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∞–Ω–æ–º–∞–ª–∏–∏: {e}")
        return 0.0


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ RMS —Ç–æ–∫–æ–≤ –¥–≤–∏–≥–∞—Ç–µ–ª–µ–π")
    parser.add_argument("equipment_id", help="UUID –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è")
    parser.add_argument("--steps", type=int, default=DEFAULT_FORECAST_STEPS,
                       help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∞")
    parser.add_argument("--model", choices=['arima', 'prophet', 'auto'], default='auto',
                       help="–¢–∏–ø –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")
    parser.add_argument("--phases", nargs="+", choices=['a', 'b', 'c'],
                       help="–§–∞–∑—ã –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Å–µ)")
    parser.add_argument("--verbose", "-v", action="store_true", help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥")
    
    args = parser.parse_args()

    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    if args.verbose:
        import logging
        logging.getLogger().setLevel(logging.DEBUG)

    async def main():
        try:
            logger.info(f"–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ RMS –¥–ª—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è {args.equipment_id}")

            results = await forecast_equipment_rms(
                equipment_id=args.equipment_id,
                forecast_steps=args.steps,
                model_type=args.model,
                phases=args.phases
            )

            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if 'summary' in results:
                summary = results['summary']
                print(f"\nüìä –°–≤–æ–¥–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è:")
                print(f"  - –§–∞–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {summary['successful_phases']}/{summary['total_phases']}")
                print(f"  - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∞–Ω–æ–º–∞–ª–∏–∏: {summary['max_anomaly_probability']:.1%}")

                if summary['critical_phases']:
                    print(f"  - –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–∑—ã:")
                    for critical in summary['critical_phases']:
                        print(f"    ‚Ä¢ –§–∞–∑–∞ {critical['phase_name']}: {critical['probability']:.1%}")

            for phase, phase_result in results['phases'].items():
                if phase_result.get('success', True):
                    anomaly = phase_result['anomaly_analysis']
                    print(f"\nüîÆ –§–∞–∑–∞ {phase.upper()}:")
                    print(f"  - –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {args.steps} —à–∞–≥–æ–≤")
                    print(f"  - –ü–æ—Ä–æ–≥ –∞–Ω–æ–º–∞–ª–∏–∏: {phase_result['threshold']:.4f}")
                    print(f"  - –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è: {anomaly['max_probability']:.1%}")
                    if anomaly['any_exceedance']:
                        print(f"  - ‚ö†Ô∏è  –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ—Ç—Å—è –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞!")
                else:
                    print(f"\n‚ùå –§–∞–∑–∞ {phase.upper()}: {phase_result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")

            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return False
    
    import asyncio
    success = asyncio.run(main())
    exit(0 if success else 1)
