"""
Prometheus –º–µ—Ç—Ä–∏–∫–∏ –∏ middleware –¥–ª—è FastAPI
"""

import time
from typing import Dict, Any, Callable
from fastapi import Request, Response
from starlette.middleware.base import BaseHTTPMiddleware
from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST

from src.utils.logger import get_logger

logger = get_logger(__name__)


class PrometheusMetrics:
    """–ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è Prometheus –º–µ—Ç—Ä–∏–∫–∞–º–∏"""

    def __init__(self):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
        self.init_metrics()

    def init_metrics(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫"""

        # HTTP –∑–∞–ø—Ä–æ—Å—ã
        self.api_requests_total = Counter(
            'api_requests_total',
            '–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ HTTP –∑–∞–ø—Ä–æ—Å–æ–≤',
            ['method', 'endpoint', 'status_code', 'user_role']
        )

        self.api_request_duration_seconds = Histogram(
            'api_request_duration_seconds',
            '–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è HTTP –∑–∞–ø—Ä–æ—Å–æ–≤',
            ['method', 'endpoint'],
            buckets=[0.1, 0.5, 1.0, 2.5, 5.0, 10.0]
        )

        # –ê–Ω–æ–º–∞–ª–∏–∏
        self.anomalies_detected_total = Counter(
            'anomalies_detected_total',
            '–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –∞–Ω–æ–º–∞–ª–∏–π',
            ['equipment_type', 'severity', 'model_name']
        )

        self.anomaly_detection_duration_seconds = Histogram(
            'anomaly_detection_duration_seconds',
            '–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π',
            buckets=[1.0, 5.0, 10.0, 30.0, 60.0, 300.0]
        )

        # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ
        self.forecast_latency_seconds = Histogram(
            'forecast_latency_seconds',
            '–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è',
            buckets=[5.0, 10.0, 30.0, 60.0, 300.0, 600.0]
        )

        self.forecasts_generated_total = Counter(
            'forecasts_generated_total',
            '–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤',
            ['equipment_type']
        )

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.signals_processed_total = Counter(
            'signals_processed_total',
            '–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤',
            ['equipment_type', 'status']
        )

        self.signal_processing_duration_seconds = Histogram(
            'signal_processing_duration_seconds',
            '–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤',
            buckets=[10.0, 30.0, 60.0, 300.0, 600.0, 1800.0]
        )

        # –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
        self.active_equipment_count = Gauge(
            'active_equipment_count',
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è'
        )

        self.processing_queue_size = Gauge(
            'processing_queue_size',
            '–†–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏'
        )

        self.database_connections_active = Gauge(
            'database_connections_active',
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π –∫ –ë–î'
        )

        # –û—à–∏–±–∫–∏
        self.api_errors_total = Counter(
            'api_errors_total',
            '–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫ API',
            ['status_code', 'error_type']
        )

        self.worker_task_failures_total = Counter(
            'worker_task_failures_total',
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ—É–¥–∞—á–Ω—ã—Ö worker –∑–∞–¥–∞—á',
            ['task_name', 'error_type']
        )

        # –§–∞–π–ª—ã
        self.files_uploaded_total = Counter(
            'files_uploaded_total',
            '–û–±—âÔøΩÔøΩ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤',
            ['file_type', 'status']
        )

        self.file_upload_size_bytes = Histogram(
            'file_upload_size_bytes',
            '–†–∞–∑–º–µ—Ä –∑–∞–≥—Ä—É–∂–∞–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ –±–∞–π—ÇÔøΩÔøΩ—Ö',
            buckets=[1024, 10240, 102400, 1048576, 10485760, 104857600]  # 1KB - 100MB
        )

        logger.info("üìä Prometheus –º–µ—Ç—Ä–∏–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")

    def increment_counter(self, metric_name: str, labels: Dict[str, str] = None):
        """–£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Å—á–µ—Ç—á–∏–∫–∞"""
        try:
            metric = getattr(self, metric_name)
            if labels:
                metric.labels(**labels).inc()
            else:
                metric.inc()
        except AttributeError:
            logger.warning(f"–ú–µ—Ç—Ä–∏–∫–∞ {metric_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    def observe_histogram(self, metric_name: str, value: float, labels: Dict[str, str] = None):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É"""
        try:
            metric = getattr(self, metric_name)
            if labels:
                metric.labels(**labels).observe(value)
            else:
                metric.observe(value)
        except AttributeError:
            logger.warning(f"–ú–µ—Ç—Ä–∏–∫–∞ {metric_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    def set_gauge(self, metric_name: str, value: float, labels: Dict[str, str] = None):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏—è gauge"""
        try:
            metric = getattr(self, metric_name)
            if labels:
                metric.labels(**labels).set(value)
            else:
                metric.set(value)
        except AttributeError:
            logger.warning(f"–ú–µ—Ç—Ä–∏–∫–∞ {metric_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    def get_metrics(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Prometheus"""
        return generate_latest()


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–µ—Ç—Ä–∏–∫
metrics = PrometheusMetrics()


class PrometheusMiddleware(BaseHTTPMiddleware):
    """Middleware –¥–ª—è —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫ HTTP –∑–∞–ø—Ä–æ—Å–æ–≤"""

    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        start_time = time.time()

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–ø—Ä–æ—Å–µ
        method = request.method
        path = request.url.path
        user_role = 'unknown'
        user_id = 'anonymous'

        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ –∏–∑ —Ç–æ–∫–µ–Ω–∞
        try:
            auth_header = request.headers.get('authorization')
            if auth_header and hasattr(request.state, 'user'):
                user_role = getattr(request.state.user, 'role', 'unknown')
                user_id = getattr(request.state.user, 'id', 'unknown')
        except Exception:
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –º–µ—Ç—Ä–∏–∫
            ...

        response = None
        status_code = 500

        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
            response = await call_next(request)
            status_code = response.status_code
            return response
        except Exception as e:
            status_code = 500
            raise
        finally:
            # –í—ã—á–∏—Å–ª—è–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            duration = time.time() - start_time

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—É—Ç—å –¥–ª—è –º–µ—Ç—Ä–∏–∫ (—É–±–∏—Ä–∞–µ–º ID –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
            normalized_path = self._normalize_path(path)

            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            metrics.increment_counter(
                'api_requests_total',
                {'method': method, 'endpoint': normalized_path, 'status_code': str(status_code), 'user_role': user_role}
            )

            metrics.observe_histogram(
                'api_request_duration_seconds',
                duration,
                {'method': method, 'endpoint': normalized_path}
            )

            # –õ–æ–≥–∏—Ä—É–µ–º –º–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            if duration > 5.0:
                logger.warning(f"–ú–µ–¥–ª–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {method} {normalized_path} –≤—ã–ø–æ–ª–Ω—è–ª—Å—è {duration:.2f}s")

    def _normalize_path(self, path: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—É—Ç–∏ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –º–µ—Ç—Ä–∏–∫"""
        # –ó–∞–º–µ–Ω—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ ID –Ω–∞ {id}
        import re
        normalized = re.sub(r'/\d+', '/{id}', path)

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ—Ö–æ–∂–∏–µ endpoints
        if '/equipment/' in normalized and '/files' in normalized:
            return '/equipment/{id}/files'
        elif '/signals/' in normalized:
            return '/signals/{id}'
        elif '/anomalies/' in normalized:
            return '/anomalies/{id}'
        elif '/features/' in normalized:
            return '/features/{id}'

        return normalized

    def _get_client_ip(self, request: Request) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ IP –∞–¥—Ä–µ—Å–∞ –∫–ª–∏–µ–Ω—Ç–∞"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ø—Ä–æ–∫—Å–∏
        forwarded_for = request.headers.get('x-forwarded-for')
        if forwarded_for:
            return forwarded_for.split(',')[0].strip()

        real_ip = request.headers.get('x-real-ip')
        if real_ip:
            return real_ip

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º IP –∏–∑ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        if hasattr(request.client, 'host'):
            return request.client.host

        return 'unknown'


# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –º–µ—Ç—Ä–∏–∫
def track_anomaly_detection(equipment_type: str, severity: str, model_name: str, duration: float):
    """–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π"""
    metrics.increment_counter(
        'anomalies_detected_total',
        {'equipment_type': equipment_type, 'severity': severity, 'model_name': model_name}
    )
    metrics.observe_histogram('anomaly_detection_duration_seconds', duration)


def track_forecast_generation(equipment_type: str, duration: float):
    """–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤"""
    metrics.increment_counter('forecasts_generated_total', {'equipment_type': equipment_type})
    metrics.observe_histogram('forecast_latency_seconds', duration)


def track_signal_processing(equipment_type: str, status: str, duration: float):
    """–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤"""
    metrics.increment_counter(
        'signals_processed_total',
        {'equipment_type': equipment_type, 'status': status}
    )
    metrics.observe_histogram('signal_processing_duration_seconds', duration)


def track_file_upload(file_type: str, status: str, file_size: int):
    """–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤"""
    metrics.increment_counter('files_uploaded_total', {'file_type': file_type, 'status': status})
    metrics.observe_histogram('file_upload_size_bytes', file_size)


def update_system_gauges(active_equipment: int, queue_size: int, db_connections: int):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö gauge –º–µ—Ç—Ä–∏–∫"""
    metrics.set_gauge('active_equipment_count', active_equipment)
    metrics.set_gauge('processing_queue_size', queue_size)
    metrics.set_gauge('database_connections_active', db_connections)
