#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –∞–Ω–æ–º–∞–ª–∏–π DiagMod
–û–±—É—á–∞–µ—Ç Isolation Forest, DBSCAN –∏ —Å–æ–∑–¥–∞–µ—Ç PCA –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
"""

import argparse
import asyncio
import sys
from pathlib import Path
from typing import List, Optional

from src.ml.train import train_anomaly_models, DEFAULT_CONTAMINATION
from src.utils.logger import get_logger

logger = get_logger(__name__)


async def train_models_cli(
    equipment_ids: Optional[List[str]] = None,
    contamination: float = DEFAULT_CONTAMINATION,
    output_dir: Optional[str] = None,
    visualizations: bool = True
):
    """–û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª–∏ –∞–Ω–æ–º–∞–ª–∏–π —á–µ—Ä–µ–∑ CLI"""
    try:
        logger.info("–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –∞–Ω–æ–º–∞–ª–∏–π")

        if equipment_ids:
            logger.info(f"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é: {equipment_ids}")

        results = await train_anomaly_models(
            equipment_ids=equipment_ids,
            contamination=contamination,
            output_dir=output_dir
        )

        # –í—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print(f"\nüéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è:")
        print(f"  ‚îî‚îÄ –í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏: {results['model_version']}")

        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã Isolation Forest
        if_results = results['isolation_forest']
        print(f"\nüå≤ Isolation Forest:")
        print(f"  ‚îú‚îÄ –ù–∞–π–¥–µ–Ω–æ –∞–Ω–æ–º–∞–ª–∏–π: {if_results['n_anomalies']}")
        print(f"  ‚îî‚îÄ –î–æ–ª—è –∞–Ω–æ–º–∞–ª–∏–π: {if_results['anomaly_ratio']:.2%}")

        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã DBSCAN
        db_results = results['dbscan']
        print(f"\nüîç DBSCAN:")
        print(f"  ‚îú‚îÄ –ö–ª–∞—Å—Ç–µ—Ä–æ–≤: {db_results['n_clusters']}")
        print(f"  ‚îú‚îÄ –ê–Ω–æ–º–∞–ª–∏–π: {db_results['n_anomalies']}")
        print(f"  ‚îî‚îÄ –î–æ–ª—è –∞–Ω–æ–º–∞–ª–∏–π: {db_results['anomaly_ratio']:.2%}")

        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã PCA
        pca_results = results['pca']
        print(f"\nüìà PCA (—Å–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏):")
        print(f"  ‚îú‚îÄ PC1: {pca_results['explained_variance_ratio'][0]:.1%} –¥–∏—Å–ø–µ—Ä—Å–∏–∏")
        print(f"  ‚îú‚îÄ PC2: {pca_results['explained_variance_ratio'][1]:.1%} –¥–∏—Å–ø–µ—Ä—Å–∏–∏")
        print(f"  ‚îî‚îÄ –û–±—â–∞—è –æ–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è: {pca_results['total_variance_explained']:.1%}")

        # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if 'feature_importance' in results:
            importance = results['feature_importance']
            if 'isolation_forest' in importance:
                top_features = importance['isolation_forest']['top_features'][:5]
                print(f"\n‚≠ê –¢–æ–ø-5 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Isolation Forest):")
                for i, (feature, score) in enumerate(top_features, 1):
                    print(f"  {i}. {feature}: {score:.4f}")

        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        if 'visualizations' in results:
            viz_paths = results['visualizations']
            print(f"\nüìä –°–æ–∑–¥–∞–Ω–Ω—ã–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏:")
            for viz_name, viz_path in viz_paths.items():
                print(f"  ‚îú‚îÄ {viz_name}: {viz_path}")

        # –†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        models_base_path = Path(output_dir) if output_dir else Path("./models/anomaly_detection")
        print(f"\nüíæ –ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:")
        print(f"  ‚îú‚îÄ –í–µ—Ä—Å–∏—è: {models_base_path}/{results['model_version']}")
        print(f"  ‚îî‚îÄ –ü–æ—Å–ª–µ–¥–Ω—è—è: {models_base_path}/latest")

        return True

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
        return False


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è CLI"""
    parser = argparse.ArgumentParser(
        description="–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∞–Ω–æ–º–∞–ª–∏–π –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –¥–≤–∏–≥–∞—Ç–µ–ª–µ–π DiagMod",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

  # –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
  python scripts/train_models.py

  # –û–±—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
  python scripts/train_models.py --equipment-ids EQ_2025_000001 EQ_2025_000002

  # –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –¥–æ–ª—é –æ–∂–∏–¥–∞–µ–º—ã—Ö –∞–Ω–æ–º–∞–ª–∏–π
  python scripts/train_models.py --contamination 0.05

  # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∫–∞—Å—Ç–æ–º–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
  python scripts/train_models.py --output-dir ./custom_models

  # –û–±—É—á–∏—Ç—å –±–µ–∑ —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π (–±—ã—Å—Ç—Ä–µ–µ)
  python scripts/train_models.py --no-visualizations
        """)

    parser.add_argument(
        "--equipment-ids",
        nargs="+",
        help="–°–ø–∏—Å–æ–∫ ID –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä: EQ_2025_000001 EQ_2025_000002)"
    )

    parser.add_argument(
        "--contamination",
        type=float,
        default=DEFAULT_CONTAMINATION,
        help=f"–û–∂–∏–¥–∞–µ–º–∞—è –¥–æ–ª—è –∞–Ω–æ–º–∞–ª–∏–π (0.0-0.5, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {DEFAULT_CONTAMINATION})"
    )

    parser.add_argument(
        "--output-dir",
        type=str,
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: ./models/anomaly_detection)"
    )

    parser.add_argument(
        "--no-visualizations",
        action="store_true",
        help="–ù–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (—É—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ)"
    )

    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥"
    )

    args = parser.parse_args()

    # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    if args.contamination < 0.0 or args.contamination > 0.5:
        print("‚ùå –î–æ–ª—è –∞–Ω–æ–º–∞–ª–∏–π –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0.0, 0.5]")
        sys.exit(1)

    if args.output_dir and not Path(args.output_dir).parent.exists():
        print(f"‚ùå –†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {args.output_dir} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        sys.exit(1)

    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    if args.verbose:
        import logging
        logging.getLogger().setLevel(logging.DEBUG)

    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
    async def run_training():
        return await train_models_cli(
            equipment_ids=args.equipment_ids,
            contamination=args.contamination,
            output_dir=args.output_dir,
            visualizations=not args.no_visualizations
        )

    try:
        print("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∞–Ω–æ–º–∞–ª–∏–π...")
        success = asyncio.run(run_training())

        if success:
            print("\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
            print("üí° –ú–æ–¥–µ–ª–∏ –≥–æ—Ç–æ–≤—ã –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —Å–∏—Å—Ç–µ–º–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏")

        sys.exit(0 if success else 1)

    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  –û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(130)
    except Exception as e:
        logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        print(f"\n‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
